{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+jVk1CTliD3EEHm2fdYFU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuncaich/TFG_Proyect/blob/main/Notebook/Preprocesado_de_imagenes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrd1y5YhhpK_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfb33d6c-a057-4061-e9bb-8630539a4fd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "from os import mkdir\n",
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from skimage import io\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "kfn6tiesvZd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Variables"
      ],
      "metadata": {
        "id": "zz-MylqzNmkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"/content/drive/MyDrive/Segmentacion/Imagen_Seccionado_128x128/volume-2\"\n",
        "url_label = \"/content/drive/MyDrive/Segmentacion/Label_Seccionado_128x128/volume-2\"\n",
        "\n",
        "path_name = os.listdir(url)\n",
        "path_name_label = os.listdir(url_label)\n",
        "\n"
      ],
      "metadata": {
        "id": "h6Tc6-6qzcf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Seccionar imagenes 3D a 2D"
      ],
      "metadata": {
        "id": "P2BQx2DMNzKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ImagesCustomDataset(Dataset):\n",
        "    \"\"\"Face Landmarks dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, root_dir_images, root_dir_label, transform=None):\n",
        "        self.transform = transform\n",
        "        volumes = list(filter(lambda x: True if 'volume-' in x else False, os.listdir(root_dir_images)))\n",
        "        self.data = []\n",
        "        self.targets = []\n",
        "        for volume_id in volumes:\n",
        "          img_dir = os.path.join(root_dir_images, volume_id)\n",
        "          target_dir = os.path.join(root_dir_label, volume_id)\n",
        "          samples = list(map(lambda x: os.path.join(img_dir, x), sorted(os.listdir(img_dir))))\n",
        "          labels = list(map(lambda x: os.path.join(target_dir, x), sorted(os.listdir(target_dir))))\n",
        "\n",
        "          self.data.extend(samples)\n",
        "          self.targets.extend(labels)\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.data[idx])\n",
        "        target = np.load(self.targets[idx])\n",
        "        if self.transform:\n",
        "          img=self.transform(img)\n",
        "\n",
        "        return (img, target)"
      ],
      "metadata": {
        "id": "egvybhqhxFDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "def read_nii(filepath):\n",
        "    '''\n",
        "    Reads .nii file and returns pixel array\n",
        "    '''\n",
        "    ct_scan = nib.load(filepath)\n",
        "    array   = ct_scan.get_fdata()\n",
        "    array   = np.rot90(np.array(array))\n",
        "    return(array)\n",
        "\n",
        "\n",
        "def segment_image(input_filepath,output_filepath):\n",
        "  contador = 0\n",
        "  path_name = os.listdir(input_filepath)\n",
        "\n",
        "  for file_name in path_name:\n",
        "    file_name_splited, _ = file_name.split('.')\n",
        "    output_file_name = output_filepath + \"/\" + file_name_splited\n",
        "    if not os.path.exists(output_file_name):\n",
        "      data = read_nii(input_filepath + \"/\" + file_name)\n",
        "\n",
        "      mkdir(output_file_name)\n",
        "      samples = np.transpose(data, (2, 0, 1))\n",
        "      \n",
        "      for i in range(samples.shape[0]):\n",
        "\n",
        "        res = cv2.resize(data[:,:,i], dsize=(128, 128))\n",
        "        cv2.imwrite(output_file_name + \"/\" + str(contador) + \".jpg\" , res )\n",
        "        contador = contador + 1\n",
        "      contador=0\n",
        "\n",
        "def interpolate(mask: np.ndarray, size = (128,128)) -> np.ndarray:\n",
        "  resized = np.array(Image.fromarray(mask*255).resize(size, Image.BILINEAR))\n",
        "  resized[resized<128] = 0\n",
        "  resized[resized>=128] = 1 \n",
        "  return resized\n",
        "\n",
        "def segment_label(input_filepath,output_filepath):\n",
        "  contador = 0\n",
        "  contador_path = 0\n",
        "  path_name = os.listdir(input_filepath)\n",
        "\n",
        "  for file_name in path_name:\n",
        "\n",
        "    cont= file_name.split(\".\")[0].split(\"-\")[1]\n",
        "    output_file_name = output_filepath + \"/\" + \"volume-\" + cont\n",
        "    \n",
        "    if not os.path.exists(output_file_name):\n",
        "      mask = read_nii(input_filepath + \"/\" + file_name)\n",
        "      mask = np.transpose(mask, (2,0,1))\n",
        "      mkdir(output_file_name)\n",
        "     \n",
        "      n_classes = len(np.unique(mask))\n",
        "      for slice in mask[:]:\n",
        "        w, h = slice.shape\n",
        "        np_mask = np.zeros((n_classes-1, w, h))\n",
        "        resized_np_mask = np.zeros((n_classes-1, 128, 128))\n",
        "  \n",
        "        for label in range(1, n_classes):\n",
        "          idx = np.where(slice==label)\n",
        "\n",
        "          #print(label, len(idx[0]))\n",
        "          label_mask = np_mask[label-1] \n",
        "          label_mask[idx] = 1\n",
        "\n",
        "          resized = interpolate(label_mask, (128,128))\n",
        "          resized_np_mask[label-1] = resized.copy()\n",
        "          #guardar array\n",
        "      \n",
        "\n",
        "        np.save(output_file_name + \"/\" + str(contador) , resized_np_mask)\n",
        "        contador = contador + 1\n",
        "      contador=0\n",
        "      contador_path = contador_path +1\n",
        "  contador_path=0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "segment_image(\"/content/drive/MyDrive/Segmentacion/imagen\",\"/content/drive/MyDrive/Segmentacion/imagen_seccionado_64x64\")\n",
        "segment_label(\"/content/drive/MyDrive/Segmentacion/label\",\"/content/drive/MyDrive/Segmentacion/label_seccionado_64x64\")\n",
        "\n"
      ],
      "metadata": {
        "id": "I_nAfJw2Ksah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Hacer una limpieza de las imagenes que aportan informacion util para entrenamiento"
      ],
      "metadata": {
        "id": "aeMskEQeN5M0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = ImagesCustomDataset(\"/content/drive/MyDrive/Segmentacion/Imagen_Seccionado_128x128\",\"/content/drive/MyDrive/Segmentacion/Label_Seccionado_128x128\")\n",
        "\n",
        "contador = 0\n",
        "for i in range(len(dataset)):\n",
        "  file_image_name = '/content/drive/MyDrive/Segmentacion/Imagen_Seccionado_128x128/volume-30/' + str(contador) + \".jpg\"\n",
        "  file_label_name = \"/content/drive/MyDrive/Segmentacion/Label_Seccionado_128x128/volume-30\"+ \"/\" + str(contador)\n",
        "  x,y = dataset[i]\n",
        "  if np.sum(y[1]) > 0:\n",
        "    np.save(file_label_name , y)\n",
        "    x.save(file_image_name)\n",
        "    contador = contador + 1\n",
        "  "
      ],
      "metadata": {
        "id": "brf1-PEYPIIB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}